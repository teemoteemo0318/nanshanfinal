{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('training_data2-2.xlsx',index_col=0)\n",
    "df2 = pd.read_excel('testing_data2-2.xlsx',index_col=0)\n",
    "X_train = df1.iloc[:,:-1]\n",
    "y_train = df1.iloc[:,-1]\n",
    "X_test = df2.iloc[:,:-1]\n",
    "y_test = df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **決策樹**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion='gini',max_depth=10)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 0.9004222203235361\n",
      "Training data score: 0.8988594310165375\n"
     ]
    }
   ],
   "source": [
    "print('Training data score: {}'.format(clf.score(X_train, y_train)))\n",
    "print('Training data score: {}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **建立Pipeline模型並自動調參數**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pipeline of transforms with a final estimator.\\nSequentially apply a list of transforms and a final estimator. \\nIntermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods. \\nThe final estimator only needs to implement fit. \\nThe transformers in the pipeline can be cached using memory argument.\\nThe purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. \\nFor this, it enables setting parameters of the various steps using their names and the parameter name separated by a ‘__’, as in the example below. \\nA step’s estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting it to ‘passthrough’ or None.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline = Pipeline([('clf',DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **決策樹**\n",
    "* 不要求對資料標準化\n",
    "* sklearn中並不能容忍特徵職的缺失\n",
    "* 可以學習忽略與任務無關的特徵，決定那些特徵是有用的\n",
    "* 支援多輸出任務\n",
    "* 小型決策樹可以使用sklearn tree模組中的export_graphviz，輕鬆解釋和視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 需要調參數的部位\n",
    "parameters = {'clf__criterion':('entropy','gini'),\n",
    "              'clf__max_depth':(10,20,30,40,50),\n",
    "              'clf__min_samples_split':(20,100,500),\n",
    "              'clf__min_samples_leaf':(2,3,4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:  7.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# grid_search.fit(X_train, y_train)\n",
    "score = cross_val_score(grid_search, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9207439528125739"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('clf',\n",
       "                                        DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                               class_weight=None,\n",
       "                                                               criterion='gini',\n",
       "                                                               max_depth=None,\n",
       "                                                               max_features=None,\n",
       "                                                               max_leaf_nodes=None,\n",
       "                                                               min_impurity_decrease=0.0,\n",
       "                                                               min_impurity_split=None,\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               presort='deprecated',\n",
       "                                                               random_state=None,\n",
       "                                                               splitter='best'))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__criterion': ('entropy', 'gini'),\n",
       "                         'clf__max_depth': (10, 20, 30, 40, 50),\n",
       "                         'clf__min_samples_leaf': (2, 3, 4),\n",
       "                         'clf__min_samples_split': (20, 100, 500)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__criterion:gini\n",
      "clf__max_depth:30\n",
      "clf__min_samples_leaf:2\n",
      "clf__min_samples_split:20\n"
     ]
    }
   ],
   "source": [
    "## 回傳最好的參數\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('{}:{}'.format(param_name,best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.920046191481926"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **混淆矩陣解讀**\n",
    "https://www.libinx.com/2018/understanding-sklearn-classification-report/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     69432\n",
      "           1       0.93      0.92      0.92     68920\n",
      "\n",
      "    accuracy                           0.92    138352\n",
      "   macro avg       0.92      0.92      0.92    138352\n",
      "weighted avg       0.92      0.92      0.92    138352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 0.9584803567210861\n",
      "Training data score: 0.9236806021530471\n"
     ]
    }
   ],
   "source": [
    "print('Training data score: {}'.format(grid_search.score(X_train, y_train)))\n",
    "print('Training data score: {}'.format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stick_level20.196 +/- 0.001\n",
      "recency_m0.180 +/- 0.001\n",
      "cust_group20.170 +/- 0.001\n",
      "DiagnosisCode_DESC0.116 +/- 0.001\n",
      "illness_desc0.102 +/- 0.001\n",
      "BundleSubtype20.093 +/- 0.001\n",
      "累積理賠金額  0.063 +/- 0.001\n",
      "REIMBURSED_YR_TW0.054 +/- 0.000\n",
      "WEALTH_LEVEL0.047 +/- 0.000\n",
      "被保人年收   0.036 +/- 0.001\n",
      "ternure_m0.023 +/- 0.000\n",
      "REG_his 0.017 +/- 0.000\n",
      "累積理賠次數  0.010 +/- 0.000\n",
      "SIN     0.010 +/- 0.000\n",
      "REG     0.009 +/- 0.000\n",
      "GENDER  0.008 +/- 0.000\n",
      "DIGI_FLG0.008 +/- 0.000\n",
      "結案月份    0.008 +/- 0.000\n",
      "被保人總資產  0.008 +/- 0.000\n",
      "具生故保險金受益人0.007 +/- 0.000\n",
      "ILP     0.007 +/- 0.000\n",
      "ILP_his 0.006 +/- 0.000\n",
      "AHa     0.006 +/- 0.000\n",
      "SIN_his 0.006 +/- 0.000\n",
      "具滿期金受益人 0.005 +/- 0.000\n",
      "AHd     0.004 +/- 0.000\n",
      "AHc     0.004 +/- 0.000\n",
      "AHb     0.004 +/- 0.000\n",
      "AHb_his 0.003 +/- 0.000\n",
      "VIP_CLASS0.002 +/- 0.000\n",
      "被保人是否為事故人0.002 +/- 0.000\n",
      "AHc_his 0.001 +/- 0.000\n",
      "AHd_his 0.001 +/- 0.000\n",
      "TOPCARD 0.000 +/- 0.000\n",
      "VIP     0.000 +/- 0.000\n",
      "AHa_his 0.000 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(grid_search, X_test, y_test,\n",
    "                           n_repeats=30,\n",
    "                           random_state=0)\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{X_test.columns[i]:<8}\"\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **不同參數的詳細結果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_clf__min_samples_leaf</th>\n",
       "      <th>param_clf__min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.563213</td>\n",
       "      <td>0.217165</td>\n",
       "      <td>0.071406</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__max_depth': 500, 'clf__min_samples_leaf...</td>\n",
       "      <td>0.908102</td>\n",
       "      <td>0.907831</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.910576</td>\n",
       "      <td>0.908653</td>\n",
       "      <td>0.908544</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.334195</td>\n",
       "      <td>0.302861</td>\n",
       "      <td>0.067406</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>{'clf__max_depth': 500, 'clf__min_samples_leaf...</td>\n",
       "      <td>0.906543</td>\n",
       "      <td>0.905632</td>\n",
       "      <td>0.905499</td>\n",
       "      <td>0.909548</td>\n",
       "      <td>0.905454</td>\n",
       "      <td>0.906535</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.406127</td>\n",
       "      <td>0.152840</td>\n",
       "      <td>0.066806</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>{'clf__max_depth': 500, 'clf__min_samples_leaf...</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.896561</td>\n",
       "      <td>0.897292</td>\n",
       "      <td>0.898454</td>\n",
       "      <td>0.896505</td>\n",
       "      <td>0.897127</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.509134</td>\n",
       "      <td>0.229263</td>\n",
       "      <td>0.063606</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__max_depth': 500, 'clf__min_samples_leaf...</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.896561</td>\n",
       "      <td>0.897292</td>\n",
       "      <td>0.898454</td>\n",
       "      <td>0.896505</td>\n",
       "      <td>0.897127</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.102302</td>\n",
       "      <td>0.229378</td>\n",
       "      <td>0.048808</td>\n",
       "      <td>0.007726</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'clf__max_depth': 500, 'clf__min_samples_leaf...</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.896561</td>\n",
       "      <td>0.897292</td>\n",
       "      <td>0.898454</td>\n",
       "      <td>0.896505</td>\n",
       "      <td>0.897127</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "22       5.563213      0.217165         0.071406        0.008236   \n",
       "23       5.334195      0.302861         0.067406        0.005161   \n",
       "24       4.406127      0.152840         0.066806        0.006432   \n",
       "25       4.509134      0.229263         0.063606        0.006408   \n",
       "26       4.102302      0.229378         0.048808        0.007726   \n",
       "\n",
       "   param_clf__max_depth param_clf__min_samples_leaf  \\\n",
       "22                  500                         100   \n",
       "23                  500                         100   \n",
       "24                  500                         500   \n",
       "25                  500                         500   \n",
       "26                  500                         500   \n",
       "\n",
       "   param_clf__min_samples_split  \\\n",
       "22                          100   \n",
       "23                          500   \n",
       "24                           20   \n",
       "25                          100   \n",
       "26                          500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "22  {'clf__max_depth': 500, 'clf__min_samples_leaf...           0.908102   \n",
       "23  {'clf__max_depth': 500, 'clf__min_samples_leaf...           0.906543   \n",
       "24  {'clf__max_depth': 500, 'clf__min_samples_leaf...           0.896825   \n",
       "25  {'clf__max_depth': 500, 'clf__min_samples_leaf...           0.896825   \n",
       "26  {'clf__max_depth': 500, 'clf__min_samples_leaf...           0.896825   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "22           0.907831           0.907556           0.910576   \n",
       "23           0.905632           0.905499           0.909548   \n",
       "24           0.896561           0.897292           0.898454   \n",
       "25           0.896561           0.897292           0.898454   \n",
       "26           0.896561           0.897292           0.898454   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "22           0.908653         0.908544        0.001079                9  \n",
       "23           0.905454         0.906535        0.001558               17  \n",
       "24           0.896505         0.897127        0.000719               19  \n",
       "25           0.896505         0.897127        0.000719               19  \n",
       "26           0.896505         0.897127        0.000719               19  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **視覺化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.export_graphviz(clf,out_file=\"tree2.dot\",feature_names=X_train.columns,class_names=['neg','pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "(graph, ) = pydot.graph_from_dot_file('tree2.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.write_png('tree2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_graphviz(clf, out_file=\"adspy_temp.dot\", feature_names=feature_names, class_names=class_names, filled = True, impurity = False)\n",
    "# from sklearn.tree import export_graphviz\n",
    "# import graphviz\n",
    "# with open(\"tree.dot\") as f:\n",
    "#     dot_graph = f.read()\n",
    "# graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate method using pydotplus, if installed.\n",
    "# import pydotplus\n",
    "# import os\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "# graph = pydotplus.graphviz.graph_from_dot_data(dot_graph)\n",
    "# graph.create_png()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **問題**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1:怎麼決定哪個feature好? future importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_tree(clf, feature_names, class_names):\n",
    "    # This function requires the pydotplus module and assumes it's been installed.\n",
    "    # In some cases (typically under Windows) even after running conda install, there is a problem where the\n",
    "    # pydotplus module is not found when running from within the notebook environment.  The following code\n",
    "    # may help to guarantee the module is installed in the current notebook environment directory.\n",
    "    #\n",
    "    # import sys; sys.executable\n",
    "    # !{sys.executable} -m pip install pydotplus\n",
    "\n",
    "    export_graphviz(clf, out_file=\"adspy_temp.dot\", feature_names=feature_names, class_names=class_names, filled = True, impurity = False)\n",
    "    with open(\"adspy_temp.dot\") as f:\n",
    "        dot_graph = f.read()\n",
    "    # Alternate method using pydotplus, if installed.\n",
    "    # graph = pydotplus.graphviz.graph_from_dot_data(dot_graph)\n",
    "    # return graph.create_png()\n",
    "    return graphviz.Source(dot_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
